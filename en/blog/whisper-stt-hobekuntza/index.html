<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Basque from speech to text: improving transcription models | Xabi Ezpeleta</title><meta name=keywords content="ai,basque,stt,whisper"><meta name=description content="Speech-to-text (STT) technology converts spoken language into written text using natural language processing. These systems are becoming increasingly important in digital interfaces, accessibility solutions, and various communication platforms.
Since 2022, I&rsquo;ve been fine-tuning the original Whisper speech recognition model for the Basque language, using the Mozilla Common Voice dataset. Compared to the original models, I&rsquo;ve seen significant improvements in performance. As the Mozilla Common Voice initiative has grown, the model&rsquo;s accuracy has continued to improve."><meta name=author content><link rel=canonical href=https://xezpeleta.github.io/en/blog/whisper-stt-hobekuntza/><link crossorigin=anonymous href=/assets/css/stylesheet.da3211e5ef867bf2b75fd5a6515cfed7195c011e8ab735694e203810a827097b.css integrity="sha256-2jIR5e+Ge/K3X9WmUVz+1xlcAR6KtzVpTiA4EKgnCXs=" rel="preload stylesheet" as=style><link rel=icon href=https://xezpeleta.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://xezpeleta.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://xezpeleta.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://xezpeleta.github.io/apple-touch-icon.png><link rel=mask-icon href=https://xezpeleta.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=eu href=https://xezpeleta.github.io/blog/whisper-stt-hobekuntza/><link rel=alternate hreflang=en href=https://xezpeleta.github.io/en/blog/whisper-stt-hobekuntza/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZJRN8P7X6R"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-ZJRN8P7X6R")}</script><meta property="og:url" content="https://xezpeleta.github.io/en/blog/whisper-stt-hobekuntza/"><meta property="og:site_name" content="Xabi Ezpeleta"><meta property="og:title" content="Basque from speech to text: improving transcription models"><meta property="og:description" content="Speech-to-text (STT) technology converts spoken language into written text using natural language processing. These systems are becoming increasingly important in digital interfaces, accessibility solutions, and various communication platforms.
Since 2022, I’ve been fine-tuning the original Whisper speech recognition model for the Basque language, using the Mozilla Common Voice dataset. Compared to the original models, I’ve seen significant improvements in performance. As the Mozilla Common Voice initiative has grown, the model’s accuracy has continued to improve."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2024-02-27T00:00:00+00:00"><meta property="article:modified_time" content="2024-02-27T00:00:00+00:00"><meta property="article:tag" content="Ai"><meta property="article:tag" content="Basque"><meta property="article:tag" content="Stt"><meta property="article:tag" content="Whisper"><meta property="og:image" content="https://xezpeleta.github.io/images/stt.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://xezpeleta.github.io/images/stt.png"><meta name=twitter:title content="Basque from speech to text: improving transcription models"><meta name=twitter:description content="Speech-to-text (STT) technology converts spoken language into written text using natural language processing. These systems are becoming increasingly important in digital interfaces, accessibility solutions, and various communication platforms.
Since 2022, I&rsquo;ve been fine-tuning the original Whisper speech recognition model for the Basque language, using the Mozilla Common Voice dataset. Compared to the original models, I&rsquo;ve seen significant improvements in performance. As the Mozilla Common Voice initiative has grown, the model&rsquo;s accuracy has continued to improve."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://xezpeleta.github.io/en/blog/"},{"@type":"ListItem","position":2,"name":"Basque from speech to text: improving transcription models","item":"https://xezpeleta.github.io/en/blog/whisper-stt-hobekuntza/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Basque from speech to text: improving transcription models","name":"Basque from speech to text: improving transcription models","description":"Speech-to-text (STT) technology converts spoken language into written text using natural language processing. These systems are becoming increasingly important in digital interfaces, accessibility solutions, and various communication platforms.\nSince 2022, I\u0026rsquo;ve been fine-tuning the original Whisper speech recognition model for the Basque language, using the Mozilla Common Voice dataset. Compared to the original models, I\u0026rsquo;ve seen significant improvements in performance. As the Mozilla Common Voice initiative has grown, the model\u0026rsquo;s accuracy has continued to improve.\n","keywords":["ai","basque","stt","whisper"],"articleBody":"Speech-to-text (STT) technology converts spoken language into written text using natural language processing. These systems are becoming increasingly important in digital interfaces, accessibility solutions, and various communication platforms.\nSince 2022, I’ve been fine-tuning the original Whisper speech recognition model for the Basque language, using the Mozilla Common Voice dataset. Compared to the original models, I’ve seen significant improvements in performance. As the Mozilla Common Voice initiative has grown, the model’s accuracy has continued to improve.\nHowever, it became clear that more voice data was needed to achieve an acceptable quality level.\nA few weeks ago, I discovered a new study from the HiTZ-Aholab research center, where they created a bilingual Nvidia NeMo model using multiple datasets: Mozilla Common Voice, OpenSLR, and the Basque Parliament corpus.\nInspired by this work, I decided to use the same data collection to improve the Whisper model. The results have improved significantly; for example, the Word Error Rate (WER) of the whisper-small-eu model has decreased from 11.84% to 7.63%.\nDatasets Based on the HiTZ-Aholab report, I used the following data collections:\nMozilla Common Voice OpenSLR Basque Parliament corpus The combination of these datasets provides greater diversity in terms of speakers, recording quality, and content domains.\nAdditionally, researcher Asier Herranz has made these datasets readily accessible: asierhv/composite_corpus_eu_v2.1. In total, 675.98 hours of training data are available.\nResults Results of the new models:\nwhisper-large-v3-eu model updated, WER: 4.84% (previously: 7.21%). whisper-medium-eu model updated, WER: 7.14% (previously: 8.80%) whisper-small-eu model updated, WER: 7.63% (previously: 11.83%) whisper-base-eu model (new), WER: 10.78% whisper-tiny-eu model (new), WER: 13.56% Note: Lower WER values indicate better performance.\nThe Basque Whisper models created are available here.\nThese evaluations were performed using the test portion of the Mozilla Common Voice 18.0 dataset.\nSimilar Alternatives In addition to the research mentioned earlier, this work published by Vicomtech is also noteworthy. Using the same dataset, they trained a Basque-Spanish Whisper model and achieved excellent results. Unfortunately, these models have not been made publicly available (as far as I know). HiTZ/stt_eu_conformer_transducer_large: A Basque Speech-to-Text model based on the Conformer-Transducer architecture. It uses Nvidia NeMo technology and achieves very impressive results: 2.79% WER. Elhuyar Aditu is also a speech recognition system that performs automatic transcriptions. It is not open source and requires a subscription, but they offer a trial option on their website. ","wordCount":"384","inLanguage":"en","image":"https://xezpeleta.github.io/images/stt.png","datePublished":"2024-02-27T00:00:00Z","dateModified":"2024-02-27T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://xezpeleta.github.io/en/blog/whisper-stt-hobekuntza/"},"publisher":{"@type":"Organization","name":"Xabi Ezpeleta","logo":{"@type":"ImageObject","url":"https://xezpeleta.github.io/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://xezpeleta.github.io/en/ accesskey=h title="Xabi Ezpeleta (Alt + H)">Xabi Ezpeleta</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://xezpeleta.github.io/ title=Euskara aria-label=Euskara>Eu</a></li></ul></div></div><ul id=menu><li><a href=https://xezpeleta.github.io/en/categories/ title=categories><span>categories</span></a></li><li><a href=https://xezpeleta.github.io/en/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Basque from speech to text: improving transcription models</h1><div class=post-meta><span title='2024-02-27 00:00:00 +0000 UTC'>February 27, 2024</span>&nbsp;|&nbsp;<span>Translations:</span><ul class=i18n_list><li><a href=https://xezpeleta.github.io/blog/whisper-stt-hobekuntza/>Eu</a></li></ul></div></header><figure class=entry-cover><img loading=eager src=https://xezpeleta.github.io/images/stt.png alt=Speech-to-text><figcaption>Basque from speech to text</figcaption></figure><div class=post-content><p>Speech-to-text (STT) technology converts spoken language into written text using natural language processing. These systems are becoming increasingly important in digital interfaces, accessibility solutions, and various communication platforms.</p><p>Since 2022, I&rsquo;ve been fine-tuning the original <a href=https://openai.com/index/whisper/>Whisper</a> speech recognition model for the Basque language, using the <a href=https://commonvoice.mozilla.org/>Mozilla Common Voice</a> dataset. Compared to the original models, I&rsquo;ve seen significant improvements in performance. As the Mozilla Common Voice initiative has grown, the model&rsquo;s accuracy has continued to improve.</p><blockquote><p>However, it became clear that more voice data was needed to achieve an acceptable quality level.</p></blockquote><p>A few weeks ago, I discovered <a href=https://www.isca-archive.org/iberspeech_2024/herranz24_iberspeech.pdf>a new study from the HiTZ-Aholab research center</a>, where they created a bilingual <em>Nvidia NeMo</em> model using multiple datasets: Mozilla Common Voice, OpenSLR, and the Basque Parliament corpus.</p><p>Inspired by this work, I decided to use the same data collection to improve the Whisper model. The results have improved significantly; for example, the <strong>Word Error Rate (WER) of the <code>whisper-small-eu</code> model has decreased from 11.84% to 7.63%</strong>.</p><h2 id=datasets>Datasets<a hidden class=anchor aria-hidden=true href=#datasets>#</a></h2><p>Based on the HiTZ-Aholab report, I used the following data collections:</p><ul><li>Mozilla Common Voice</li><li>OpenSLR</li><li>Basque Parliament corpus</li></ul><p>The combination of these datasets provides greater diversity in terms of speakers, recording quality, and content domains.</p><p>Additionally, researcher Asier Herranz has made these datasets readily accessible: <a href=https://huggingface.co/datasets/asierhv/composite_corpus_eu_v2.1>asierhv/composite_corpus_eu_v2.1</a>. In total, <strong>675.98 hours of training data</strong> are available.</p><h2 id=results>Results<a hidden class=anchor aria-hidden=true href=#results>#</a></h2><p>Results of the new models:</p><ul><li><code>whisper-large-v3-eu</code> model updated, <strong>WER: 4.84%</strong> (previously: 7.21%).</li><li><code>whisper-medium-eu</code> model updated, <strong>WER: 7.14%</strong> (previously: 8.80%)</li><li><code>whisper-small-eu</code> model updated, <strong>WER: 7.63%</strong> (previously: 11.83%)</li><li><code>whisper-base-eu</code> model (new), <strong>WER: 10.78%</strong></li><li><code>whisper-tiny-eu</code> model (new), <strong>WER: 13.56%</strong></li></ul><p><em>Note: Lower WER values indicate better performance.</em></p><p>The Basque <strong>Whisper</strong> models created are <a href=https://huggingface.co/collections/xezpeleta/whisper-basque-fine-tuning-67b05797b023991df1715a51>available here</a>.</p><p>These evaluations were performed using the <code>test</code> portion of the <code>Mozilla Common Voice 18.0</code> dataset.</p><h2 id=similar-alternatives>Similar Alternatives<a hidden class=anchor aria-hidden=true href=#similar-alternatives>#</a></h2><ul><li>In addition to the research mentioned earlier, <a href=https://www.isca-archive.org/iberspeech_2024/vasquezcorrea24_iberspeech.pdf>this work published by Vicomtech</a> is also noteworthy. Using the same dataset, they trained a Basque-Spanish <em>Whisper</em> model and achieved <strong>excellent results</strong>. Unfortunately, these models <strong>have not been made publicly available</strong> (as far as I know).</li><li><a href=https://huggingface.co/HiTZ/stt_eu_conformer_transducer_large>HiTZ/stt_eu_conformer_transducer_large</a>: A Basque Speech-to-Text model based on the Conformer-Transducer architecture. It uses Nvidia NeMo technology and achieves <strong>very impressive results</strong>: 2.79% WER.</li><li><a href=https://aditu.eus/>Elhuyar Aditu</a> is also a speech recognition system that performs automatic transcriptions. It is not open source and requires a subscription, but they offer a trial option on their website.</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://xezpeleta.github.io/en/tags/ai/>Ai</a></li><li><a href=https://xezpeleta.github.io/en/tags/basque/>Basque</a></li><li><a href=https://xezpeleta.github.io/en/tags/stt/>Stt</a></li><li><a href=https://xezpeleta.github.io/en/tags/whisper/>Whisper</a></li></ul></footer></article></main><footer class=footer><span>Copyright © 2021, Xabier Ezpeleta. License <a href=https://creativecommons.org/licenses/by-sa/4.0/>CC BY-SA 4.0</a>.</span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>