<!doctype html><html lang=eu dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Euskara hortzetik hitzera: transkripzio ereduak hobetzen | Xabi Ezpeleta</title>
<meta name=keywords content="ai,euskara,stt,whisper"><meta name=description content="2022tik hasita, Mozilla Common Voice datu sorta erabiliz, jatorrizko Whisper STT (speech-to-text) eredua trebatzen joan naiz euskaraz hobeto egiteko (fine-tuning bat eginez). STT ereduek ahotsa testu bihurtzen dute, hizkuntza naturalaren prozesamendu automatikoan oinarrituta.
Jatorrizko ereduekin alderatuta, emaitza asko hobetzen zela ikusten zen. Eta, Mozilla Common Voice ekimena handitu hala, eredua askoz hobeto zebilen.

Baina aldi berean, kalitate maila minimo bat izateko, ahots datu gehiagoren beharra ere garbi geratzen zen.
Duela aste batzuk, HiTZ-Aholab ikerketa zentroko lan berri bat aurkitu nuen, non Nvidia NeMo eredu elebidun bat sortu duten hainbat datu sorta ezberdin erabiliz: Mozilla Common Voice, OpenSLR eta Eusko Legebiltzarreko korpusa."><meta name=author content><link rel=canonical href=https://xezpeleta.github.io/blog/whisper-stt-hobekuntza/><link crossorigin=anonymous href=/assets/css/stylesheet.45e028aa8ce0961349adf411b013ee39406be2c0bc80d4ea3fc04555f7f4611a.css integrity="sha256-ReAoqozglhNJrfQRsBPuOUBr4sC8gNTqP8BFVff0YRo=" rel="preload stylesheet" as=style><link rel=icon href=https://xezpeleta.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://xezpeleta.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://xezpeleta.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://xezpeleta.github.io/apple-touch-icon.png><link rel=mask-icon href=https://xezpeleta.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=eu href=https://xezpeleta.github.io/blog/whisper-stt-hobekuntza/><link rel=alternate hreflang=en href=https://xezpeleta.github.io/en/blog/whisper-stt-hobekuntza/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZJRN8P7X6R"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-ZJRN8P7X6R")}</script><meta property="og:url" content="https://xezpeleta.github.io/blog/whisper-stt-hobekuntza/"><meta property="og:site_name" content="Xabi Ezpeleta"><meta property="og:title" content="Euskara hortzetik hitzera: transkripzio ereduak hobetzen"><meta property="og:description" content="2022tik hasita, Mozilla Common Voice datu sorta erabiliz, jatorrizko Whisper STT (speech-to-text) eredua trebatzen joan naiz euskaraz hobeto egiteko (fine-tuning bat eginez). STT ereduek ahotsa testu bihurtzen dute, hizkuntza naturalaren prozesamendu automatikoan oinarrituta.
Jatorrizko ereduekin alderatuta, emaitza asko hobetzen zela ikusten zen. Eta, Mozilla Common Voice ekimena handitu hala, eredua askoz hobeto zebilen.
Baina aldi berean, kalitate maila minimo bat izateko, ahots datu gehiagoren beharra ere garbi geratzen zen.
Duela aste batzuk, HiTZ-Aholab ikerketa zentroko lan berri bat aurkitu nuen, non Nvidia NeMo eredu elebidun bat sortu duten hainbat datu sorta ezberdin erabiliz: Mozilla Common Voice, OpenSLR eta Eusko Legebiltzarreko korpusa."><meta property="og:locale" content="eu"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2024-03-20T00:00:00+00:00"><meta property="article:modified_time" content="2024-03-20T00:00:00+00:00"><meta property="article:tag" content="Ai"><meta property="article:tag" content="Euskara"><meta property="article:tag" content="Stt"><meta property="article:tag" content="Whisper"><meta property="og:image" content="https://xezpeleta.github.io/images/stt.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://xezpeleta.github.io/images/stt.png"><meta name=twitter:title content="Euskara hortzetik hitzera: transkripzio ereduak hobetzen"><meta name=twitter:description content="2022tik hasita, Mozilla Common Voice datu sorta erabiliz, jatorrizko Whisper STT (speech-to-text) eredua trebatzen joan naiz euskaraz hobeto egiteko (fine-tuning bat eginez). STT ereduek ahotsa testu bihurtzen dute, hizkuntza naturalaren prozesamendu automatikoan oinarrituta.
Jatorrizko ereduekin alderatuta, emaitza asko hobetzen zela ikusten zen. Eta, Mozilla Common Voice ekimena handitu hala, eredua askoz hobeto zebilen.

Baina aldi berean, kalitate maila minimo bat izateko, ahots datu gehiagoren beharra ere garbi geratzen zen.
Duela aste batzuk, HiTZ-Aholab ikerketa zentroko lan berri bat aurkitu nuen, non Nvidia NeMo eredu elebidun bat sortu duten hainbat datu sorta ezberdin erabiliz: Mozilla Common Voice, OpenSLR eta Eusko Legebiltzarreko korpusa."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://xezpeleta.github.io/blog/"},{"@type":"ListItem","position":2,"name":"Euskara hortzetik hitzera: transkripzio ereduak hobetzen","item":"https://xezpeleta.github.io/blog/whisper-stt-hobekuntza/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Euskara hortzetik hitzera: transkripzio ereduak hobetzen","name":"Euskara hortzetik hitzera: transkripzio ereduak hobetzen","description":"2022tik hasita, Mozilla Common Voice datu sorta erabiliz, jatorrizko Whisper STT (speech-to-text) eredua trebatzen joan naiz euskaraz hobeto egiteko (fine-tuning bat eginez). STT ereduek ahotsa testu bihurtzen dute, hizkuntza naturalaren prozesamendu automatikoan oinarrituta.\nJatorrizko ereduekin alderatuta, emaitza asko hobetzen zela ikusten zen. Eta, Mozilla Common Voice ekimena handitu hala, eredua askoz hobeto zebilen.\nBaina aldi berean, kalitate maila minimo bat izateko, ahots datu gehiagoren beharra ere garbi geratzen zen.\nDuela aste batzuk, HiTZ-Aholab ikerketa zentroko lan berri bat aurkitu nuen, non Nvidia NeMo eredu elebidun bat sortu duten hainbat datu sorta ezberdin erabiliz: Mozilla Common Voice, OpenSLR eta Eusko Legebiltzarreko korpusa.\n","keywords":["ai","euskara","stt","whisper"],"articleBody":"2022tik hasita, Mozilla Common Voice datu sorta erabiliz, jatorrizko Whisper STT (speech-to-text) eredua trebatzen joan naiz euskaraz hobeto egiteko (fine-tuning bat eginez). STT ereduek ahotsa testu bihurtzen dute, hizkuntza naturalaren prozesamendu automatikoan oinarrituta.\nJatorrizko ereduekin alderatuta, emaitza asko hobetzen zela ikusten zen. Eta, Mozilla Common Voice ekimena handitu hala, eredua askoz hobeto zebilen.\nBaina aldi berean, kalitate maila minimo bat izateko, ahots datu gehiagoren beharra ere garbi geratzen zen.\nDuela aste batzuk, HiTZ-Aholab ikerketa zentroko lan berri bat aurkitu nuen, non Nvidia NeMo eredu elebidun bat sortu duten hainbat datu sorta ezberdin erabiliz: Mozilla Common Voice, OpenSLR eta Eusko Legebiltzarreko korpusa.\nLan honek inspiratuta, datu bilduma bera erabiltzea erabaki dut Whisper eredua hobetzeko. Emaitzak nabarmen hobetu dira; adibide modura, whisper-small-eu ereduaren WER (Word Error Rate) errorea %11.84tik %7.63ra jaitsi da.\nDatu sortak HiTZ-Aholab txosten horretan oinarrituta, honako datu bilduma hauek erabili ditut:\nMozilla Common Voice OpenSLR Basque Parliament Dataset hauen konbinazioak aniztasun handiagoa eskaintzen du, bai hizlarien aldetik, bai grabazio kalitatearen aldetik, eta baita testuinguru eta gai desberdinen aldetik ere.\nGainera, gauzak errezteko, datu hauek modu errezean erabiltzeko prest utzi ditu Asier Herranz ikerlariak: asierhv/composite_corpus_eu_v2.1. Guztira, entrenamendu datu kopurua: 675.98 ordu ditugu eskuragarri.\nEmaitzak Eredu berrien emaitzak:\nwhisper-large-v3-eu eredua eguneratu da, WER: 4.84 (lehenago: 7.21). whisper-medium-eu eredua eguneratu da, WER: 7.14 (lehenago: 8.80) whisper-small-eu eredua eguneratu da, WER: 7.63 (lehenago: 11.83) whisper-base-eu eredua (berria), WER: 10.78 whisper-tiny-eu eredua (berria), WER: 13.56 Oharra: geroz eta WER balio txikiagoa, hobea.\nSortutako euskarazko Whisper ereduak eskuragarri dituzue hemen\nEbaluazio hauek Mozilla Common Voice 18.0 dataset-aren test zatia erabiliz egin dira.\nAntzeko alternatibak Lehen aipatutako ikerketaz gain, Vicomtech-ek argitaratu duen beste lan hau ere interesgarria da. Ildo beretik, eta datu sorta berdina erabiliz, euskara-gaztelerazko Whisper eredua trebatu dute eta emaitza bikainak lortu dituzte. Tamalez, eredu hauek ez dituzte eskuragarri utzi (nik dakidala). HiTZ/stt_eu_conformer_transducer_large Basque Speech-to-Text model Conformer-Transducer. Nvidia NeMo ereduan oinarrituta eta emaitza oso onak dituenak: 2.79% WER. Elhuyar Aditu ere transkripzio automatikoak egiten dituen hizketa ezagutzailea da. Ez da software askea eta ordainpekoa da, bainan haien webgunetik probatzeko aukera eskeintzen dute. ","wordCount":"338","inLanguage":"eu","image":"https://xezpeleta.github.io/images/stt.png","datePublished":"2024-03-20T00:00:00Z","dateModified":"2024-03-20T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://xezpeleta.github.io/blog/whisper-stt-hobekuntza/"},"publisher":{"@type":"Organization","name":"Xabi Ezpeleta","logo":{"@type":"ImageObject","url":"https://xezpeleta.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://xezpeleta.github.io/ accesskey=h title="Xabi Ezpeleta (Alt + H)">Xabi Ezpeleta</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://xezpeleta.github.io/en/ title=English aria-label=English>En</a></li></ul></div></div><ul id=menu><li><a href=https://xezpeleta.github.io/categories/ title=kategoriak><span>kategoriak</span></a></li><li><a href=https://xezpeleta.github.io/tags/ title=etiketak><span>etiketak</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Euskara hortzetik hitzera: transkripzio ereduak hobetzen</h1><div class=post-meta><span title='2024-03-20 00:00:00 +0000 UTC'>martxoa 20, 2024</span>&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://xezpeleta.github.io/en/blog/whisper-stt-hobekuntza/>En</a></li></ul></div></header><figure class=entry-cover><img loading=eager src=https://xezpeleta.github.io/images/stt.png alt=Speech-to-text><p>Euskara hortzetik hitzera</p></figure><div class=post-content><p>2022tik hasita, <a href=https://commonvoice.mozilla.org/>Mozilla Common Voice</a> datu sorta erabiliz, jatorrizko <a href=https://openai.com/index/whisper/>Whisper</a> STT (<em>speech-to-text</em>) eredua trebatzen joan naiz euskaraz hobeto egiteko (<a href=https://en.wikipedia.org/wiki/Fine-tuning_%28deep_learning%29><em>fine-tuning</em></a> bat eginez). <em>STT</em> ereduek ahotsa testu bihurtzen dute, hizkuntza naturalaren prozesamendu automatikoan oinarrituta.</p><p>Jatorrizko ereduekin alderatuta, emaitza asko hobetzen zela ikusten zen. Eta, Mozilla Common Voice ekimena handitu hala, eredua askoz hobeto zebilen.</p><blockquote><p>Baina aldi berean, kalitate maila minimo bat izateko, ahots datu gehiagoren beharra ere garbi geratzen zen.</p></blockquote><p>Duela aste batzuk, <a href=https://www.isca-archive.org/iberspeech_2024/herranz24_iberspeech.pdf>HiTZ-Aholab ikerketa zentroko lan berri bat</a> aurkitu nuen, non <em>Nvidia NeMo</em> eredu elebidun bat sortu duten hainbat datu sorta ezberdin erabiliz: Mozilla Common Voice, OpenSLR eta Eusko Legebiltzarreko korpusa.</p><p>Lan honek inspiratuta, datu bilduma bera erabiltzea erabaki dut Whisper eredua hobetzeko. Emaitzak nabarmen hobetu dira; adibide modura, <code>whisper-small-eu</code> ereduaren <strong>WER (Word Error Rate) errorea %11.84tik %7.63ra jaitsi da</strong>.</p><h2 id=datu-sortak>Datu sortak<a hidden class=anchor aria-hidden=true href=#datu-sortak>#</a></h2><p>HiTZ-Aholab txosten horretan oinarrituta, honako datu bilduma hauek erabili ditut:</p><ul><li>Mozilla Common Voice</li><li>OpenSLR</li><li>Basque Parliament</li></ul><p>Dataset hauen konbinazioak aniztasun handiagoa eskaintzen du, bai hizlarien aldetik, bai grabazio kalitatearen aldetik, eta baita testuinguru eta gai desberdinen aldetik ere.</p><p>Gainera, gauzak errezteko, datu hauek modu errezean erabiltzeko prest utzi ditu Asier Herranz ikerlariak: <a href=https://huggingface.co/datasets/asierhv/composite_corpus_eu_v2.1>asierhv/composite_corpus_eu_v2.1</a>. Guztira, <strong>entrenamendu datu kopurua: 675.98 ordu</strong> ditugu eskuragarri.</p><h2 id=emaitzak>Emaitzak<a hidden class=anchor aria-hidden=true href=#emaitzak>#</a></h2><p>Eredu berrien emaitzak:</p><ul><li><code>whisper-large-v3-eu</code> eredua eguneratu da, <strong>WER: 4.84</strong> (lehenago: 7.21).</li><li><code>whisper-medium-eu</code> eredua eguneratu da, <strong>WER: 7.14</strong> (lehenago: 8.80)</li><li><code>whisper-small-eu</code> eredua eguneratu da, <strong>WER: 7.63</strong> (lehenago: 11.83)</li><li><code>whisper-base-eu</code> eredua (berria), <strong>WER: 10.78</strong></li><li><code>whisper-tiny-eu</code> eredua (berria), <strong>WER: 13.56</strong></li></ul><p><em>Oharra: geroz eta WER balio txikiagoa, hobea.</em></p><p>Sortutako euskarazko <strong>Whisper</strong> ereduak <a href=https://huggingface.co/collections/xezpeleta/whisper-basque-fine-tuning-67b05797b023991df1715a51>eskuragarri dituzue hemen</a></p><p>Ebaluazio hauek <code>Mozilla Common Voice 18.0</code> dataset-aren <code>test</code> zatia erabiliz egin dira.</p><h2 id=antzeko-alternatibak>Antzeko alternatibak<a hidden class=anchor aria-hidden=true href=#antzeko-alternatibak>#</a></h2><ul><li>Lehen aipatutako ikerketaz gain, <a href=https://www.isca-archive.org/iberspeech_2024/vasquezcorrea24_iberspeech.pdf>Vicomtech-ek argitaratu duen</a> beste lan hau ere interesgarria da. Ildo beretik, eta datu sorta berdina erabiliz, euskara-gaztelerazko <em>Whisper</em> eredua trebatu dute eta <strong>emaitza bikainak</strong> lortu dituzte. Tamalez, eredu hauek <strong>ez dituzte eskuragarri utzi</strong> (nik dakidala).</li><li><a href=https://huggingface.co/HiTZ/stt_eu_conformer_transducer_large>HiTZ/stt_eu_conformer_transducer_large</a> Basque Speech-to-Text model Conformer-Transducer. Nvidia NeMo ereduan oinarrituta eta <strong>emaitza oso onak</strong> dituenak: 2.79% WER.</li><li><a href=https://aditu.eus/>Elhuyar Aditu</a> ere transkripzio automatikoak egiten dituen <em>hizketa ezagutzailea</em> da. Ez da software askea eta ordainpekoa da, bainan haien webgunetik probatzeko aukera eskeintzen dute.</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://xezpeleta.github.io/tags/ai/>Ai</a></li><li><a href=https://xezpeleta.github.io/tags/euskara/>Euskara</a></li><li><a href=https://xezpeleta.github.io/tags/stt/>Stt</a></li><li><a href=https://xezpeleta.github.io/tags/whisper/>Whisper</a></li></ul></footer></article></main><footer class=footer><span>Copyright © 2021, Xabier Ezpeleta. License <a href=https://creativecommons.org/licenses/by-sa/4.0/>CC BY-SA 4.0</a>.</span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>